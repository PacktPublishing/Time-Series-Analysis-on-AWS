{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1baf74c4",
   "metadata": {},
   "source": [
    "# Time series analysis on AWS\n",
    "*Chapter 9 - Creating a dataset and ingesting your data*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba931c3",
   "metadata": {},
   "source": [
    "## Initializations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet tqdm kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b27fd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44909eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mpl_colors\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8057e",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA = os.path.join('..', 'Data', 'raw')\n",
    "DATA = os.path.join('..', 'Data')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.makedirs(RAW_DATA, exist_ok=True)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['lines.linewidth'] = 0.3\n",
    "plt.rcParams['axes.titlesize'] = 6\n",
    "plt.rcParams['axes.labelsize'] = 6\n",
    "plt.rcParams['xtick.labelsize'] = 5\n",
    "plt.rcParams['ytick.labelsize'] = 5\n",
    "plt.rcParams['grid.linewidth'] = 0.2\n",
    "plt.rcParams['legend.fontsize'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c104b772",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_report_hook(count, block_size, total_size):\n",
    "    mb = int(count * block_size // 1048576)\n",
    "    if count % 500 == 0:\n",
    "        sys.stdout.write(\"\\r{} MB downloaded\".format(mb))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67742269",
   "metadata": {},
   "source": [
    "### Downloading datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48f20a",
   "metadata": {},
   "source": [
    "#### **Dataset 4:** Industrial pump data\n",
    "To download this dataset from Kaggle, you will need to have an account and create a token that you install on your machine. You can follow [**this link**](https://www.kaggle.com/docs/api) to get started with the Kaggle API. Once generated, make sure your Kaggle token is stored in the `~/.kaggle/kaggle.json` file, or the next cells will issue an error. To get a Kaggle token, go to kaggle.com and create an account. Then navigate to **My account** and scroll down to the API section. There, click the **Create new API token** button:\n",
    "\n",
    "<img src=\"../Assets/kaggle_api.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME    = 'pump-sensor-data.zip'\n",
    "ARCHIVE_PATH = os.path.join(RAW_DATA, FILE_NAME)\n",
    "FILE_PATH    = os.path.join(DATA, 'pump', 'sensor.csv')\n",
    "FILE_DIR     = os.path.dirname(FILE_PATH)\n",
    "\n",
    "if not os.path.isfile(FILE_PATH):\n",
    "    if not os.path.exists('/home/ec2-user/.kaggle/kaggle.json'):\n",
    "        os.makedirs('/home/ec2-user/.kaggle/', exist_ok=True)\n",
    "        raise Exception('The kaggle.json token was not found.\\nCreating the /home/ec2-user/.kaggle/ directory: put your kaggle.json file there once you have generated it from the Kaggle website')\n",
    "    else:\n",
    "        print('The kaggle.json token file was found: making sure it is not readable by other users on this system.')\n",
    "        !chmod 600 /home/ec2-user/.kaggle/kaggle.json\n",
    "\n",
    "    os.makedirs(os.path.join(DATA, 'pump'), exist_ok=True)\n",
    "    !kaggle datasets download -d nphantawee/pump-sensor-data -p $RAW_DATA\n",
    "\n",
    "    print(\"\\nExtracting data archive\")\n",
    "    zip_ref = zipfile.ZipFile(ARCHIVE_PATH, 'r')\n",
    "    zip_ref.extractall(FILE_DIR + '/')\n",
    "    zip_ref.close()\n",
    "    \n",
    "else:\n",
    "    print(\"File found, skipping download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c7f2c",
   "metadata": {},
   "source": [
    "## Dataset visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5cc41",
   "metadata": {},
   "source": [
    "### **4.** Industrial pump data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c07a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = os.path.join(DATA, 'pump', 'sensor.csv')\n",
    "pump_df = pd.read_csv(FILE_PATH, sep=',')\n",
    "pump_df.drop(columns={'Unnamed: 0'}, inplace=True)\n",
    "pump_df['timestamp'] = pd.to_datetime(pump_df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "pump_df = pump_df.set_index('timestamp')\n",
    "\n",
    "pump_df['machine_status'].replace(to_replace='NORMAL', value=np.nan, inplace=True)\n",
    "pump_df['machine_status'].replace(to_replace='BROKEN', value=1, inplace=True)\n",
    "pump_df['machine_status'].replace(to_replace='RECOVERING', value=1, inplace=True)\n",
    "\n",
    "print('Shape:', pump_df.shape)\n",
    "pump_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_structure_df = pump_df.iloc[:, 0:10].resample('5D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['hatch.linewidth'] = 0.5\n",
    "plt.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "fig = plt.figure(figsize=(5,1))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "plot1 = ax1.plot(pump_df['sensor_00'], label='Healthy pump')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "plot2 = ax2.fill_between(\n",
    "    x=pump_df.index, \n",
    "    y1=0.0, \n",
    "    y2=pump_df['machine_status'], \n",
    "    color=colors[1], \n",
    "    linewidth=0.0,\n",
    "    edgecolor='#000000',\n",
    "    alpha=0.5, \n",
    "    hatch=\"//////\", \n",
    "    label='Broken pump'\n",
    ")\n",
    "ax2.grid(False)\n",
    "ax2.set_yticks([])\n",
    "\n",
    "labels = [plot1[0].get_label(), plot2.get_label()]\n",
    "\n",
    "plt.legend(handles=[plot1[0], plot2], labels=labels, loc='lower center', ncol=2, bbox_to_anchor=(0.5, -.4))\n",
    "plt.title('Industrial pump sensor data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32caf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = np.min(pump_df.index)\n",
    "end_date = np.max(pump_df.index)\n",
    "num_periods = pump_df.shape[0]\n",
    "\n",
    "new_index = pd.date_range(start=start_date, periods=num_periods, freq='5min')\n",
    "pump_df.index = new_index\n",
    "pump_df.index.name = 'Timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['hatch.linewidth'] = 0.5\n",
    "plt.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "fig = plt.figure(figsize=(5,1))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "plot1 = ax1.plot(pump_df['sensor_00'], label='sensor_00')\n",
    "# plot1 = ax1.plot(pump_df['sensor_34'], label='Healthy sensor_34')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "plot2 = ax2.fill_between(\n",
    "    x=pump_df.index, \n",
    "    y1=0.0, \n",
    "    y2=pump_df['machine_status'], \n",
    "    color=colors[1], \n",
    "    linewidth=0.0,\n",
    "    edgecolor='#000000',\n",
    "    alpha=0.5, \n",
    "    hatch=\"//////\", \n",
    "    label='Broken pump'\n",
    ")\n",
    "ax2.grid(False)\n",
    "ax2.set_yticks([])\n",
    "\n",
    "labels = [plot1[0].get_label(), plot2.get_label()]\n",
    "\n",
    "plt.legend(handles=[plot1[0], plot2], labels=labels, loc='lower center', ncol=2, bbox_to_anchor=(0.5, -.4))\n",
    "plt.title('Industrial pump sensor data')\n",
    "\n",
    "# start = pd.to_datetime('2018-06-24 14:25')\n",
    "# end = pd.to_datetime('2018-07-06 09:40')\n",
    "# plt.xlim(start, end)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlesize'] = 4\n",
    "plt.rcParams['axes.labelsize'] = 4\n",
    "plt.rcParams['xtick.labelsize'] = 3\n",
    "plt.rcParams['ytick.labelsize'] = 3\n",
    "\n",
    "for f in list(pump_df.columns):\n",
    "    fig = plt.figure(figsize=(2.5,0.5))\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    plot1 = ax1.plot(pump_df[f])\n",
    "    ax1.set_title(f)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ef77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pump_df = pump_df.drop(columns=['sensor_50', 'sensor_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pump_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48650f84",
   "metadata": {},
   "source": [
    "## Preparing the dataset for Lookout for Equipment\n",
    "---\n",
    "### Preparing time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18768b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = os.path.join('..', 'Data', 'pump', 'train-data')\n",
    "LABEL_DATA = os.path.join('..', 'Data', 'pump', 'label-data')\n",
    "\n",
    "os.makedirs(TRAIN_DATA, exist_ok=True)\n",
    "os.makedirs(LABEL_DATA, exist_ok=True)\n",
    "\n",
    "pump_df.index.name = 'Timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pump_df.columns)[:-1]\n",
    "\n",
    "for tag in tqdm(features):\n",
    "    os.makedirs(os.path.join(TRAIN_DATA, tag), exist_ok=True)\n",
    "    fname = os.path.join(TRAIN_DATA, tag, 'tag_data.csv')\n",
    "    tag_df = pump_df[[tag]]\n",
    "    tag_df.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec31d8",
   "metadata": {},
   "source": [
    "### Preparing label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4843119",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labels = pump_df[['machine_status']]\n",
    "expanded_labels['machine_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "range_df = expanded_labels.copy()\n",
    "range_df['BROKEN'] = False\n",
    "range_df.loc[range_df['machine_status'] == 1.0, 'BROKEN'] = True\n",
    "\n",
    "range_df['Next Status'] = range_df['BROKEN'].shift(-1)\n",
    "range_df['Start Range'] = (range_df['BROKEN'] == False) & (range_df['Next Status'] == True)\n",
    "range_df['End Range'] = (range_df['BROKEN'] == True) & (range_df['Next Status'] == False)\n",
    "range_df.iloc[0,3] = range_df.iloc[0,1]\n",
    "range_df = range_df[(range_df['Start Range'] == True) | (range_df['End Range'] == True)]\n",
    "\n",
    "labels_df = pd.DataFrame(columns=['start', 'end'])\n",
    "for index, row in range_df.iterrows():\n",
    "    if row['Start Range']:\n",
    "        start = index\n",
    "\n",
    "    if row['End Range']:\n",
    "        end = index\n",
    "        labels_df = labels_df.append({\n",
    "            'start': start + relativedelta(hours=-12),\n",
    "            'end': end + relativedelta(hours=+12)\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "labels_fname = os.path.join(LABEL_DATA, 'labels.csv')\n",
    "labels_df['start'] = pd.to_datetime(labels_df['start'])\n",
    "labels_df['end'] = pd.to_datetime(labels_df['end'])\n",
    "labels_df['start'] = labels_df['start'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "labels_df['end'] = labels_df['end'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "labels_df.to_csv(labels_fname, header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388aa1c",
   "metadata": {},
   "source": [
    "## Creating schema\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23965ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for managing Lookout for Equipment API calls:\n",
    "sys.path.append('../../amazon-lookout-for-equipment-python-sdk/src')\n",
    "import lookoutequipment as lookout\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b51e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'pump'\n",
    "BUCKET       = 'pump-anomaly-detection'\n",
    "PREFIX       = 'train-data/'\n",
    "ROLE_ARN     = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ba6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset = lookout.LookoutEquipmentDataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    component_root_dir=TRAIN_DATA,\n",
    "    access_role_arn=ROLE_ARN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1463753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset.dataset_schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
